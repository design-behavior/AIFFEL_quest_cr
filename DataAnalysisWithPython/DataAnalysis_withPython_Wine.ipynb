{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOzrklGUHDtTzhOeLqwRY7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/design-behavior/AIFFEL_quest_cr/blob/main/DataAnalysisWithPython/DataAnalysis_withPython_Wine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkXV16_7PM0I",
        "outputId": "8587ac14-98fc-46d3-b7bb-02c250988975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- sklearn version :  1.6.1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<<wine 정보 이해하기>>\n",
            "- 변수와 메서드 :  ['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']\n",
            "- 데이터셋 키 :  dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])\n",
            "- 특성 이름 :  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
            "- 타겟 이름 :  ['class_0' 'class_1' 'class_2']\n",
            "- 데이터의 첫 번째 샘플 :  [1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
            " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
            "- 타겟의 첫 번째 샘플 :  0\n",
            "- 데이터 크기 :  (178, 13)\n",
            "- 타겟 크기 :  (178,)\n",
            "\n",
            "   count\n",
            "0     59\n",
            "1     71\n",
            "2     48\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<<Decision Tree>>\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        12\n",
            "           1       0.85      0.92      0.88        12\n",
            "           2       0.91      0.83      0.87        12\n",
            "\n",
            "    accuracy                           0.92        36\n",
            "   macro avg       0.92      0.92      0.92        36\n",
            "weighted avg       0.92      0.92      0.92        36\n",
            "\n",
            "\n",
            "confussion matrix\n",
            "[[12  0  0]\n",
            " [ 0 11  1]\n",
            " [ 0  2 10]]\n",
            "\n",
            "Decision Tree: 91.66666666666666 \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<<Random Forest>>\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        12\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n",
            "\n",
            "confussion matrix\n",
            "[[12  0  0]\n",
            " [ 0 12  0]\n",
            " [ 0  0 12]]\n",
            "\n",
            "Random Forest :  100.0 \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<<SVM_model>>\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.92      0.85        12\n",
            "           1       0.50      0.92      0.65        12\n",
            "           2       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.61        36\n",
            "   macro avg       0.43      0.61      0.50        36\n",
            "weighted avg       0.43      0.61      0.50        36\n",
            "\n",
            "\n",
            "confussion matrix\n",
            "[[11  1  0]\n",
            " [ 1 11  0]\n",
            " [ 2 10  0]]\n",
            "\n",
            "SVM_model :  61.111111111111114 \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<<SGD Classifier>>\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.92      0.81        12\n",
            "           1       0.80      0.67      0.73        12\n",
            "           2       0.73      0.67      0.70        12\n",
            "\n",
            "    accuracy                           0.75        36\n",
            "   macro avg       0.75      0.75      0.75        36\n",
            "weighted avg       0.75      0.75      0.75        36\n",
            "\n",
            "\n",
            "confussion matrix\n",
            "[[11  0  1]\n",
            " [ 2  8  2]\n",
            " [ 2  2  8]]\n",
            "\n",
            "SGD Classifier :  75.0 \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<<Logistic Regression>>\n",
            "\n",
            "<<Logistic Regression 사용해 보기>>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.42      0.34        12\n",
            "           1       0.33      0.33      0.33        12\n",
            "           2       1.00      0.58      0.74        12\n",
            "\n",
            "    accuracy                           0.44        36\n",
            "   macro avg       0.54      0.44      0.47        36\n",
            "weighted avg       0.54      0.44      0.47        36\n",
            "\n",
            "\n",
            "confussion matrix\n",
            "[[5 7 0]\n",
            " [8 4 0]\n",
            " [4 1 7]]\n",
            "\n",
            "Logistic Regression :  44.44444444444444 \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# (1) 필요한 모듈 import하기\n",
        "import sklearn\n",
        "print(\"- sklearn version : \", sklearn.__version__)\n",
        "print('-' * 100 )\n",
        "\n",
        "from sklearn.datasets import load_wine #싸이킷런 데이터셋에 있는 wine를 불러오기 위한 import\n",
        "from sklearn.model_selection import train_test_split #싸이킷런에 있는 데이터를 train과 test dataset으로 나누어주는 함수 import\n",
        "from sklearn.metrics import classification_report #싸이킷런에 있는 분류 결과에 대한 시각화를 위한 import\n",
        "\n",
        "# (2) 데이터 준비하기\n",
        "wine = load_wine() #wine 데이터 전체를 불러온다.\n",
        "wine_data = wine.data #wine 데이터의 data컬럼을 분류해 wine_data 변수에 담는다.\n",
        "wine_label = wine.target #wine 데이터의 target컬럼을 분류해 digits_label 변수에 담는다.\n",
        "\n",
        "\n",
        "# (3) 데이터 이해하기\n",
        "print(\"<<wine 정보 이해하기>>\")\n",
        "# 데이터셋의 기본 정보 출력\n",
        "print(\"- 변수와 메서드 : \", dir(wine))\n",
        "print(\"- 데이터셋 키 : \", wine.keys())\n",
        "print(\"- 특성 이름 : \", wine.feature_names)\n",
        "print(\"- 타겟 이름 : \", wine.target_names)\n",
        "print(\"- 데이터의 첫 번째 샘플 : \", wine_data[0])\n",
        "print(\"- 타겟의 첫 번째 샘플 : \", wine_label[0])\n",
        "\n",
        "# 데이터의 크기 확인\n",
        "print(\"- 데이터 크기 : \", wine_data.shape)\n",
        "print(\"- 타겟 크기 : \", wine_label.shape)\n",
        "\n",
        "print()\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "df_class_counts = pd.DataFrame(pd.Series(wine.target).value_counts())\n",
        "df_class_counts.sort_index()\n",
        "print(df_class_counts.sort_index())\n",
        "\n",
        "print()\n",
        "\n",
        "# 데이터 Describe\n",
        "wine_df = pd.DataFrame(data=wine_data, columns=wine.feature_names)\n",
        "wine_df.describe()\n",
        "\n",
        "print('-' * 100 )\n",
        "\n",
        "# (4) train, test 데이터 분리하기\n",
        "#train_test_split()를 사용하여 X값, y값을 각각 train data와 test data로 나눈다. 함수에 들어 갈 파라미터로는 x,y가 들어가고\n",
        "#test_size는 몇대몇으로 나눌지 정하는 옵션, random_state는 랜덤 패턴의 값을 지정한다.\n",
        "X_train, X_test, y_train, y_test = train_test_split(wine_data,\n",
        "                                                    wine_label,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=15)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier #싸이킷런에 있는 결정트리분류기를 사용하기 위한 import\n",
        "from sklearn.ensemble import RandomForestClassifier #랜덤포레스트라는 분류기를 사용하기 위한 import\n",
        "from sklearn import svm #Support Vector Machine을 사용하기 위해 import\n",
        "from sklearn.linear_model import SGDClassifier #선형분류기인 SGDClassifier를 사용하기 위한 import\n",
        "from sklearn.linear_model import LogisticRegression #선형분류기인 LogisticRegression를 사용하기 위한 import\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix #싸이킷런에 있는 분류 결과에 대한 시각화를 위한 import\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# (5) 다양한 모델로 학습 및 예측하기\n",
        "# (5-1) Decision Tree 사용해 보기\n",
        "print('<<Decision Tree>>')\n",
        "print()\n",
        "decision_tree = DecisionTreeClassifier(random_state=32) #결정트리분류기의 객체 생성\n",
        "decision_tree.fit(X_train, y_train) #분류기에 x와 y의 훈련 데이터를 넣어 훈련\n",
        "decision_tree_pred = decision_tree.predict(X_test) #훈련된 분류기에 X_test라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인 => y_pred를 각 모델별로 새로 계산하도록 변경(결과가 잘못된 해석으로 이어질 수 있음을 예방하기 위해 / classification_report와 confusion_matrix가 올바른 예측값을 참조하도록 하기 위해)\n",
        "print(classification_report(y_test, decision_tree_pred, zero_division=0)) #결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred 값을 넣어 확인, #**zero_division=0 추가**\n",
        "print()\n",
        "print(\"confussion matrix\")\n",
        "decision_tree_conf_matrix = confusion_matrix(y_test, decision_tree_pred)\n",
        "decision_tree_accuracy = accuracy_score(y_test, decision_tree_pred)\n",
        "print(decision_tree_conf_matrix)\n",
        "print()\n",
        "print(\"Decision Tree:\", decision_tree_accuracy*100,'\\n')\n",
        "print()\n",
        "print('-' * 100 )\n",
        "\n",
        "\n",
        "# (5-2) Random Forest 사용해 보기\n",
        "print('<<Random Forest>>')\n",
        "print()\n",
        "random_forest = RandomForestClassifier(random_state=32) #RandomForest분류기의 객체 생성\n",
        "random_forest.fit(X_train, y_train) #분류기에 x와 y의 훈련 데이터를 넣어 훈련\n",
        "random_forest_pred = random_forest.predict(X_test) #훈련된 분류기에 X_test라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인 => y_pred를 각 모델별로 새로 계산하도록 변경(결과가 잘못된 해석으로 이어질 수 있음을 예방하기 위해 / classification_report와 confusion_matrix가 올바른 예측값을 참조하도록 하기 위해)\n",
        "print(classification_report(y_test, random_forest_pred, zero_division=0)) #결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred 값을 넣어 확인, #**zero_division=0 추가**\n",
        "print()\n",
        "print(\"confussion matrix\")\n",
        "random_forest_conf_matrix = confusion_matrix(y_test, random_forest_pred)\n",
        "random_forest_accuracy = accuracy_score(y_test, random_forest_pred)\n",
        "print(random_forest_conf_matrix)\n",
        "print()\n",
        "print(\"Random Forest : \", random_forest_accuracy*100,'\\n')\n",
        "print()\n",
        "print('-' * 100 )\n",
        "\n",
        "# (5-3) SVM 사용해 보기\n",
        "print('<<SVM_model>>')\n",
        "print()\n",
        "svm_model = svm.SVC(random_state=32) #분류기의 객체 생성\n",
        "svm_model.fit(X_train, y_train) #분류기에 x와 y의 훈련 데이터를 넣어 훈련\n",
        "svm_model_pred = svm_model.predict(X_test) #훈련된 분류기에 X_test라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인 => y_pred를 각 모델별로 새로 계산하도록 변경(결과가 잘못된 해석으로 이어질 수 있음을 예방하기 위해 / classification_report와 confusion_matrix가 올바른 예측값을 참조하도록 하기 위해)\n",
        "print(classification_report(y_test, svm_model_pred, zero_division=0)) #결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred 값을 넣어 확인, #**zero_division=0 추가**\n",
        "print()\n",
        "print(\"confussion matrix\")\n",
        "svm_model_conf_matrix = confusion_matrix(y_test, svm_model_pred)\n",
        "svm_model_accuracy = accuracy_score(y_test, svm_model_pred)\n",
        "print(svm_model_conf_matrix)\n",
        "print()\n",
        "print(\"SVM_model : \", svm_model_accuracy*100,'\\n')\n",
        "print()\n",
        "print('-' * 100 )\n",
        "\n",
        "# (5-4) SGD Classifier 사용해 보기\n",
        "print('<<SGD Classifier>>')\n",
        "print()\n",
        "sgd_model = SGDClassifier(random_state=32) #분류기의 객체 생성\n",
        "sgd_model.fit(X_train, y_train) #분류기에 x와 y의 훈련 데이터를 넣어 훈련\n",
        "sgd_model_pred = sgd_model.predict(X_test) #훈련된 분류기에 X_test라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인 => y_pred를 각 모델별로 새로 계산하도록 변경(결과가 잘못된 해석으로 이어질 수 있음을 예방하기 위해 / classification_report와 confusion_matrix가 올바른 예측값을 참조하도록 하기 위해)\n",
        "print(classification_report(y_test, sgd_model_pred, zero_division=0)) #결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred 값을 넣어 확인, #**zero_division=0 추가**\n",
        "print()\n",
        "print(\"confussion matrix\")\n",
        "sgd_model_conf_matrix = confusion_matrix(y_test, sgd_model_pred)\n",
        "sgd_model_accuracy = accuracy_score(y_test, sgd_model_pred)\n",
        "print(sgd_model_conf_matrix)\n",
        "print()\n",
        "print(\"SGD Classifier : \", sgd_model_accuracy*100,'\\n')\n",
        "print()\n",
        "print('-' * 100 )\n",
        "\n",
        "\n",
        "# (5-5) Logistic Regression 사용해 보기\n",
        "print('<<Logistic Regression>>')\n",
        "print()\n",
        "print('<<Logistic Regression 사용해 보기>>')\n",
        "scaler = StandardScaler()  #**StandardScaler 추가**\n",
        "X_train_scaled = scaler.fit_transform(X_train)  #**학습 데이터 스케일링**\n",
        "X_test_scaled = scaler.transform(X_test)  #**테스트 데이터 스케일링**\n",
        "\n",
        "logistic_model = LogisticRegression(random_state=32, max_iter=1000) #분류기의 객체 생성 (디폴트 max_iter 값이 충분하지 않을 수 있어, max_iter=1000을 설정해 경고 방지)\n",
        "logistic_model.fit(X_train_scaled, y_train) #분류기에 x와 y의 훈련 데이터를 넣어 훈련\n",
        "logistic_model_pred = logistic_model.predict(X_test_scaled)#훈련된 분류기에 X_test_scaled 라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인 => y_pred를 각 모델별로 새로 계산하도록 변경(결과가 잘못된 해석으로 이어질 수 있음을 예방하기 위해 / classification_report와 confusion_matrix가 올바른 예측값을 참조하도록 하기 위해)\n",
        "print(classification_report(y_test, logistic_model_pred, zero_division=0)) #결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred 값을 넣어 확인, #**zero_division=0 추가**\n",
        "print()\n",
        "print(\"confussion matrix\")\n",
        "logistic_model_conf_matrix = confusion_matrix(y_test, logistic_model_pred)\n",
        "logistic_model_accuracy = accuracy_score(y_test, logistic_model_pred)\n",
        "print(logistic_model_conf_matrix)\n",
        "print()\n",
        "print(\"Logistic Regression : \", logistic_model_accuracy*100,'\\n')\n",
        "print()\n",
        "print('-' * 100 )"
      ]
    }
  ]
}