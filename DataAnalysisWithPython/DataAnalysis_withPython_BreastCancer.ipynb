{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJo0nh5usZqCbZ2B6nWNhP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/design-behavior/AIFFEL_quest_cr/blob/main/DataAnalysisWithPython/DataAnalysis_withPython_BreastCancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbNGfa_paktv",
        "outputId": "6b0cff62-f284-4ade-9332-f3573ba4c970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- sklearn version :  1.6.1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<<breast_cancer 정보 이해하기>>\n",
            "- 변수와 메서드 :  ['DESCR', 'data', 'data_module', 'feature_names', 'filename', 'frame', 'target', 'target_names']\n",
            "- 데이터셋 키 :  dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
            "- 특성 이름 :  ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
            "- 타겟 이름 :  ['malignant' 'benign']\n",
            "- 데이터의 첫 번째 샘플 :  [1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
            " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
            " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
            " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
            " 4.601e-01 1.189e-01]\n",
            "- 타겟의 첫 번째 샘플 :  0\n",
            "- 데이터 크기 :  (569, 30)\n",
            "- 타겟 크기 :  (569,)\n",
            "\n",
            "   count\n",
            "0    212\n",
            "1    357\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<<Decision Tree>>\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.87      0.92        39\n",
            "           1       0.94      0.99      0.96        75\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.95      0.93      0.94       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n",
            "\n",
            "confussion matrix\n",
            "[[34  5]\n",
            " [ 1 74]]\n",
            "\n",
            "Decision Tree: 94.73684210526315 \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<<Random Forest>>\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.87      0.91        39\n",
            "           1       0.94      0.97      0.95        75\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.94      0.92      0.93       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n",
            "\n",
            "confussion matrix\n",
            "[[34  5]\n",
            " [ 2 73]]\n",
            "\n",
            "Random Forest :  93.85964912280701 \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<<SVM_model>>\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.67      0.78        39\n",
            "           1       0.85      0.97      0.91        75\n",
            "\n",
            "    accuracy                           0.87       114\n",
            "   macro avg       0.89      0.82      0.84       114\n",
            "weighted avg       0.88      0.87      0.86       114\n",
            "\n",
            "\n",
            "confussion matrix\n",
            "[[26 13]\n",
            " [ 2 73]]\n",
            "\n",
            "SVM_model :  86.8421052631579 \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<<SGD Classifier>>\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.85      0.79        39\n",
            "           1       0.91      0.84      0.88        75\n",
            "\n",
            "    accuracy                           0.84       114\n",
            "   macro avg       0.82      0.84      0.83       114\n",
            "weighted avg       0.85      0.84      0.84       114\n",
            "\n",
            "\n",
            "confussion matrix\n",
            "[[33  6]\n",
            " [12 63]]\n",
            "\n",
            "SGD Classifier :  84.21052631578947 \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<<Logistic Regression>>\n",
            "\n",
            "<<Logistic Regression 사용해 보기>>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.03      0.05      0.04        39\n",
            "           1       0.33      0.24      0.28        75\n",
            "\n",
            "    accuracy                           0.18       114\n",
            "   macro avg       0.18      0.15      0.16       114\n",
            "weighted avg       0.23      0.18      0.20       114\n",
            "\n",
            "\n",
            "confussion matrix\n",
            "[[ 2 37]\n",
            " [57 18]]\n",
            "\n",
            "Logistic Regression :  17.543859649122805 \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# (1) 필요한 모듈 import하기\n",
        "import sklearn\n",
        "print(\"- sklearn version : \", sklearn.__version__)\n",
        "print('-' * 100 )\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer #싸이킷런 데이터셋에 있는 breast_cancer를 불러오기 위한 import\n",
        "from sklearn.model_selection import train_test_split #싸이킷런에 있는 데이터를 train과 test dataset으로 나누어주는 함수 import\n",
        "from sklearn.metrics import classification_report #싸이킷런에 있는 분류 결과에 대한 시각화를 위한 import\n",
        "\n",
        "# (2) 데이터 준비하기\n",
        "breast_cancer = load_breast_cancer() #breast_cancer 데이터 전체를 불러온다.\n",
        "breast_cancer_data = breast_cancer.data #breast_cancer 데이터의 data컬럼을 분류해 breast_cancer_data 변수에 담는다.\n",
        "breast_cancer_label = breast_cancer.target #breast_cancer 데이터의 target컬럼을 분류해 breast_cancer_label 변수에 담는다.\n",
        "\n",
        "\n",
        "# (3) 데이터 이해하기\n",
        "print(\"<<breast_cancer 정보 이해하기>>\")\n",
        "# 데이터셋의 기본 정보 출력\n",
        "print(\"- 변수와 메서드 : \", dir(breast_cancer))\n",
        "print(\"- 데이터셋 키 : \", breast_cancer.keys())\n",
        "print(\"- 특성 이름 : \", breast_cancer.feature_names)\n",
        "print(\"- 타겟 이름 : \", breast_cancer.target_names)\n",
        "print(\"- 데이터의 첫 번째 샘플 : \", breast_cancer_data[0])\n",
        "print(\"- 타겟의 첫 번째 샘플 : \", breast_cancer_label[0])\n",
        "\n",
        "# 데이터의 크기 확인\n",
        "print(\"- 데이터 크기 : \", breast_cancer_data.shape)\n",
        "print(\"- 타겟 크기 : \", breast_cancer_label.shape)\n",
        "\n",
        "print()\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "df_class_counts = pd.DataFrame(pd.Series(breast_cancer.target).value_counts())\n",
        "df_class_counts.sort_index()\n",
        "print(df_class_counts.sort_index())\n",
        "\n",
        "print()\n",
        "\n",
        "# plt.imshow(breast_cancer.data[0].reshape(8, 8), cmap='gray') --> \"cannot reshape array of size 30 into shape (8,8)\"\n",
        "# plt.axis('off')\n",
        "# plt.show()\n",
        "\n",
        "# print('-' * 100 )\n",
        "\n",
        "# for i in range(10):\n",
        "#   plt.subplot(2, 5, i+1)\n",
        "#   plt.imshow(breast_cancer.data[i].reshape(8, 8), cmap='gray')\n",
        "#   plt.axis('off')\n",
        "# plt.show()\n",
        "\n",
        "# print('-' * 100 )\n",
        "\n",
        "# 데이터 Describe\n",
        "breast_cancer_df = pd.DataFrame(data=breast_cancer_data, columns=breast_cancer.feature_names)\n",
        "breast_cancer_df.describe()\n",
        "\n",
        "print('-' * 100 )\n",
        "\n",
        "# (4) train, test 데이터 분리하기\n",
        "#train_test_split()를 사용하여 X값, y값을 각각 train data와 test data로 나눈다. 함수에 들어 갈 파라미터로는 x,y가 들어가고\n",
        "#test_size는 몇대몇으로 나눌지 정하는 옵션, random_state는 랜덤 패턴의 값을 지정한다.\n",
        "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_data,\n",
        "                                                    breast_cancer_label,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=15)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier #싸이킷런에 있는 결정트리분류기를 사용하기 위한 import\n",
        "from sklearn.ensemble import RandomForestClassifier #랜덤포레스트라는 분류기를 사용하기 위한 import\n",
        "from sklearn import svm #Support Vector Machine을 사용하기 위해 import\n",
        "from sklearn.linear_model import SGDClassifier #선형분류기인 SGDClassifier를 사용하기 위한 import\n",
        "from sklearn.linear_model import LogisticRegression #선형분류기인 LogisticRegression를 사용하기 위한 import\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix #싸이킷런에 있는 분류 결과에 대한 시각화를 위한 import\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# (5) 다양한 모델로 학습 및 예측하기\n",
        "# (5-1) Decision Tree 사용해 보기\n",
        "print('<<Decision Tree>>')\n",
        "print()\n",
        "decision_tree = DecisionTreeClassifier(random_state=32) #결정트리분류기의 객체 생성\n",
        "decision_tree.fit(X_train, y_train) #분류기에 x와 y의 훈련 데이터를 넣어 훈련\n",
        "decision_tree_pred = decision_tree.predict(X_test) #훈련된 분류기에 X_test라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인 => y_pred를 각 모델별로 새로 계산하도록 변경(결과가 잘못된 해석으로 이어질 수 있음을 예방하기 위해 / classification_report와 confusion_matrix가 올바른 예측값을 참조하도록 하기 위해)\n",
        "print(classification_report(y_test, decision_tree_pred, zero_division=0)) #결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred 값을 넣어 확인, #**zero_division=0 추가**\n",
        "print()\n",
        "print(\"confussion matrix\")\n",
        "decision_tree_conf_matrix = confusion_matrix(y_test, decision_tree_pred)\n",
        "decision_tree_accuracy = accuracy_score(y_test, decision_tree_pred)\n",
        "print(decision_tree_conf_matrix)\n",
        "print()\n",
        "print(\"Decision Tree:\", decision_tree_accuracy*100,'\\n')\n",
        "print()\n",
        "print('-' * 100 )\n",
        "\n",
        "\n",
        "# (5-2) Random Forest 사용해 보기\n",
        "print('<<Random Forest>>')\n",
        "print()\n",
        "random_forest = RandomForestClassifier(random_state=32) #RandomForest분류기의 객체 생성\n",
        "random_forest.fit(X_train, y_train) #분류기에 x와 y의 훈련 데이터를 넣어 훈련\n",
        "random_forest_pred = random_forest.predict(X_test) #훈련된 분류기에 X_test라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인 => y_pred를 각 모델별로 새로 계산하도록 변경(결과가 잘못된 해석으로 이어질 수 있음을 예방하기 위해 / classification_report와 confusion_matrix가 올바른 예측값을 참조하도록 하기 위해)\n",
        "print(classification_report(y_test, random_forest_pred, zero_division=0)) #결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred 값을 넣어 확인, #**zero_division=0 추가**\n",
        "print()\n",
        "print(\"confussion matrix\")\n",
        "random_forest_conf_matrix = confusion_matrix(y_test, random_forest_pred)\n",
        "random_forest_accuracy = accuracy_score(y_test, random_forest_pred)\n",
        "print(random_forest_conf_matrix)\n",
        "print()\n",
        "print(\"Random Forest : \", random_forest_accuracy*100,'\\n')\n",
        "print()\n",
        "print('-' * 100 )\n",
        "\n",
        "# (5-3) SVM 사용해 보기\n",
        "print('<<SVM_model>>')\n",
        "print()\n",
        "svm_model = svm.SVC(random_state=32) #분류기의 객체 생성\n",
        "svm_model.fit(X_train, y_train) #분류기에 x와 y의 훈련 데이터를 넣어 훈련\n",
        "svm_model_pred = svm_model.predict(X_test) #훈련된 분류기에 X_test라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인 => y_pred를 각 모델별로 새로 계산하도록 변경(결과가 잘못된 해석으로 이어질 수 있음을 예방하기 위해 / classification_report와 confusion_matrix가 올바른 예측값을 참조하도록 하기 위해)\n",
        "print(classification_report(y_test, svm_model_pred, zero_division=0)) #결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred 값을 넣어 확인, #**zero_division=0 추가**\n",
        "print()\n",
        "print(\"confussion matrix\")\n",
        "svm_model_conf_matrix = confusion_matrix(y_test, svm_model_pred)\n",
        "svm_model_accuracy = accuracy_score(y_test, svm_model_pred)\n",
        "print(svm_model_conf_matrix)\n",
        "print()\n",
        "print(\"SVM_model : \", svm_model_accuracy*100,'\\n')\n",
        "print()\n",
        "print('-' * 100 )\n",
        "\n",
        "# (5-4) SGD Classifier 사용해 보기\n",
        "print('<<SGD Classifier>>')\n",
        "print()\n",
        "sgd_model = SGDClassifier(random_state=32) #분류기의 객체 생성\n",
        "sgd_model.fit(X_train, y_train) #분류기에 x와 y의 훈련 데이터를 넣어 훈련\n",
        "sgd_model_pred = sgd_model.predict(X_test) #훈련된 분류기에 X_test라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인 => y_pred를 각 모델별로 새로 계산하도록 변경(결과가 잘못된 해석으로 이어질 수 있음을 예방하기 위해 / classification_report와 confusion_matrix가 올바른 예측값을 참조하도록 하기 위해)\n",
        "print(classification_report(y_test, sgd_model_pred, zero_division=0)) #결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred 값을 넣어 확인, #**zero_division=0 추가**\n",
        "print()\n",
        "print(\"confussion matrix\")\n",
        "sgd_model_conf_matrix = confusion_matrix(y_test, sgd_model_pred)\n",
        "sgd_model_accuracy = accuracy_score(y_test, sgd_model_pred)\n",
        "print(sgd_model_conf_matrix)\n",
        "print()\n",
        "print(\"SGD Classifier : \", sgd_model_accuracy*100,'\\n')\n",
        "print()\n",
        "print('-' * 100 )\n",
        "\n",
        "\n",
        "# (5-5) Logistic Regression 사용해 보기\n",
        "print('<<Logistic Regression>>')\n",
        "print()\n",
        "print('<<Logistic Regression 사용해 보기>>')\n",
        "scaler = StandardScaler()  #**StandardScaler 추가**\n",
        "X_train_scaled = scaler.fit_transform(X_train)  #**학습 데이터 스케일링**\n",
        "X_test_scaled = scaler.transform(X_test)  #**테스트 데이터 스케일링**\n",
        "\n",
        "logistic_model = LogisticRegression(random_state=32, max_iter=1000) #분류기의 객체 생성 (디폴트 max_iter 값이 충분하지 않을 수 있어, max_iter=1000을 설정해 경고 방지)\n",
        "logistic_model.fit(X_train_scaled, y_train) #분류기에 x와 y의 훈련 데이터를 넣어 훈련\n",
        "logistic_model_pred = logistic_model.predict(X_test_scaled) #훈련된 분류기에 X_test_scaled라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인 => y_pred를 각 모델별로 새로 계산하도록 변경(결과가 잘못된 해석으로 이어질 수 있음을 예방하기 위해 / classification_report와 confusion_matrix가 올바른 예측값을 참조하도록 하기 위해)\n",
        "print(classification_report(y_test, logistic_model_pred, zero_division=0)) #결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred 값을 넣어 확인, #**zero_division=0 추가**\n",
        "print()\n",
        "print(\"confussion matrix\")\n",
        "logistic_model_conf_matrix = confusion_matrix(y_test, logistic_model_pred)\n",
        "logistic_model_accuracy = accuracy_score(y_test, logistic_model_pred)\n",
        "print(logistic_model_conf_matrix)\n",
        "print()\n",
        "print(\"Logistic Regression : \", logistic_model_accuracy*100,'\\n')\n",
        "print()\n",
        "print('-' * 100 )"
      ]
    }
  ]
}