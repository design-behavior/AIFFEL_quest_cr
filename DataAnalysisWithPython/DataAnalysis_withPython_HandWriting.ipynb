{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHl/WyvLNfQA67sihcCvgu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/design-behavior/AIFFEL_quest_cr/blob/main/DataAnalysisWithPython/DataAnalysis_withPython_HandWriting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rr_PMegpC_zW",
        "outputId": "dc659b2e-8f78-4c86-aa83-2aac613805eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- sklearn version :  1.6.1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<<digits 정보 이해하기>>\n",
            "- 변수와 메서드 :  ['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']\n",
            "- 데이터셋 키 :  dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n",
            "- 특성 이름 :  ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n",
            "- 타겟 이름 :  [0 1 2 3 4 5 6 7 8 9]\n",
            "- 데이터의 첫 번째 샘플 :  [ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
            " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
            "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
            "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n",
            "- 타겟의 첫 번째 샘플 :  0\n",
            "- 데이터 크기 :  (1797, 64)\n",
            "- 타겟 크기 :  (1797,)\n",
            "\n",
            "   count\n",
            "0    178\n",
            "1    182\n",
            "2    177\n",
            "3    183\n",
            "4    181\n",
            "5    182\n",
            "6    181\n",
            "7    179\n",
            "8    174\n",
            "9    180\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<<Decision Tree>>\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97        31\n",
            "           1       0.82      0.82      0.82        38\n",
            "           2       0.72      0.87      0.79        38\n",
            "           3       0.85      0.81      0.83        27\n",
            "           4       0.97      0.78      0.86        41\n",
            "           5       0.82      0.89      0.85        35\n",
            "           6       0.85      0.89      0.87        38\n",
            "           7       0.91      0.91      0.91        34\n",
            "           8       0.74      0.74      0.74        35\n",
            "           9       0.83      0.79      0.81        43\n",
            "\n",
            "    accuracy                           0.84       360\n",
            "   macro avg       0.85      0.84      0.84       360\n",
            "weighted avg       0.85      0.84      0.84       360\n",
            "\n",
            "\n",
            "confussion matrix\n",
            "[[29  0  0  0  0  0  0  0  2  0]\n",
            " [ 0 31  3  1  1  0  1  0  1  0]\n",
            " [ 0  1 33  1  0  1  0  0  1  1]\n",
            " [ 0  0  0 22  0  1  1  0  2  1]\n",
            " [ 0  0  0  1 32  0  4  3  0  1]\n",
            " [ 0  0  3  0  0 31  0  0  1  0]\n",
            " [ 0  1  2  0  0  1 34  0  0  0]\n",
            " [ 0  0  0  1  0  0  0 31  0  2]\n",
            " [ 0  2  3  0  0  2  0  0 26  2]\n",
            " [ 0  3  2  0  0  2  0  0  2 34]]\n",
            "\n",
            "Decision Tree Accuracy :  84.16666666666667 \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<<Random Forest>>\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.94      0.95        31\n",
            "           1       0.95      0.97      0.96        38\n",
            "           2       1.00      1.00      1.00        38\n",
            "           3       1.00      0.96      0.98        27\n",
            "           4       0.95      1.00      0.98        41\n",
            "           5       0.97      1.00      0.99        35\n",
            "           6       1.00      0.95      0.97        38\n",
            "           7       1.00      1.00      1.00        34\n",
            "           8       0.94      0.97      0.96        35\n",
            "           9       1.00      0.98      0.99        43\n",
            "\n",
            "    accuracy                           0.98       360\n",
            "   macro avg       0.98      0.98      0.98       360\n",
            "weighted avg       0.98      0.98      0.98       360\n",
            "\n",
            "\n",
            "confussion matrix\n",
            "[[29  0  0  0  2  0  0  0  0  0]\n",
            " [ 0 37  0  0  0  1  0  0  0  0]\n",
            " [ 0  0 38  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 26  0  0  0  0  1  0]\n",
            " [ 0  0  0  0 41  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 35  0  0  0  0]\n",
            " [ 1  1  0  0  0  0 36  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 34  0  0]\n",
            " [ 0  1  0  0  0  0  0  0 34  0]\n",
            " [ 0  0  0  0  0  0  0  0  1 42]]\n",
            "\n",
            "Random Forest Accuracy :  97.77777777777777 \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<<SVM_model>>\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98        31\n",
            "           1       0.95      1.00      0.97        38\n",
            "           2       1.00      1.00      1.00        38\n",
            "           3       0.96      0.96      0.96        27\n",
            "           4       0.98      0.98      0.98        41\n",
            "           5       1.00      1.00      1.00        35\n",
            "           6       1.00      1.00      1.00        38\n",
            "           7       1.00      1.00      1.00        34\n",
            "           8       0.97      0.94      0.96        35\n",
            "           9       0.98      0.98      0.98        43\n",
            "\n",
            "    accuracy                           0.98       360\n",
            "   macro avg       0.98      0.98      0.98       360\n",
            "weighted avg       0.98      0.98      0.98       360\n",
            "\n",
            "\n",
            "confussion matrix\n",
            "[[30  0  0  0  1  0  0  0  0  0]\n",
            " [ 0 38  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 38  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 26  0  0  0  0  1  0]\n",
            " [ 0  0  0  0 40  0  0  0  0  1]\n",
            " [ 0  0  0  0  0 35  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 38  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 34  0  0]\n",
            " [ 0  2  0  0  0  0  0  0 33  0]\n",
            " [ 0  0  0  1  0  0  0  0  0 42]]\n",
            "\n",
            "SVM_model Accuracy :  98.33333333333333 \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<<SGD Classifier>>\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98        31\n",
            "           1       0.97      0.82      0.89        38\n",
            "           2       1.00      0.95      0.97        38\n",
            "           3       0.96      0.85      0.90        27\n",
            "           4       0.98      0.98      0.98        41\n",
            "           5       0.97      1.00      0.99        35\n",
            "           6       1.00      0.97      0.99        38\n",
            "           7       0.97      1.00      0.99        34\n",
            "           8       0.67      0.97      0.79        35\n",
            "           9       0.97      0.86      0.91        43\n",
            "\n",
            "    accuracy                           0.94       360\n",
            "   macro avg       0.95      0.94      0.94       360\n",
            "weighted avg       0.95      0.94      0.94       360\n",
            "\n",
            "\n",
            "confussion matrix\n",
            "[[30  0  0  0  1  0  0  0  0  0]\n",
            " [ 0 31  0  0  0  0  0  0  7  0]\n",
            " [ 0  0 36  0  0  0  0  0  2  0]\n",
            " [ 0  0  0 23  0  1  0  0  2  1]\n",
            " [ 0  0  0  0 40  0  0  0  1  0]\n",
            " [ 0  0  0  0  0 35  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 37  0  1  0]\n",
            " [ 0  0  0  0  0  0  0 34  0  0]\n",
            " [ 0  1  0  0  0  0  0  0 34  0]\n",
            " [ 0  0  0  1  0  0  0  1  4 37]]\n",
            "\n",
            "SGD Classifier Accuracy :  93.61111111111111 \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<<Logistic Regression>>\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98        31\n",
            "           1       0.95      0.97      0.96        38\n",
            "           2       1.00      0.97      0.99        38\n",
            "           3       0.96      0.93      0.94        27\n",
            "           4       0.95      0.98      0.96        41\n",
            "           5       0.97      0.97      0.97        35\n",
            "           6       1.00      0.97      0.99        38\n",
            "           7       1.00      1.00      1.00        34\n",
            "           8       0.89      0.97      0.93        35\n",
            "           9       0.98      0.95      0.96        43\n",
            "\n",
            "    accuracy                           0.97       360\n",
            "   macro avg       0.97      0.97      0.97       360\n",
            "weighted avg       0.97      0.97      0.97       360\n",
            "\n",
            "\n",
            "confussion matrix\n",
            "[[30  0  0  0  1  0  0  0  0  0]\n",
            " [ 0 37  0  0  0  0  0  0  1  0]\n",
            " [ 0  1 37  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 25  0  1  0  0  1  0]\n",
            " [ 0  0  0  0 40  0  0  0  1  0]\n",
            " [ 0  0  0  0  0 34  0  0  0  1]\n",
            " [ 0  1  0  0  0  0 37  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 34  0  0]\n",
            " [ 0  0  0  0  1  0  0  0 34  0]\n",
            " [ 0  0  0  1  0  0  0  0  1 41]]\n",
            "\n",
            "Logistic Regression Accuracy :  96.94444444444444 \n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# (1) 필요한 모듈 import하기\n",
        "import sklearn\n",
        "print(\"- sklearn version : \", sklearn.__version__)\n",
        "print('-' * 100 )\n",
        "\n",
        "from sklearn.datasets import load_digits #싸이킷런 데이터셋에 있는 digits를 불러오기 위한 import\n",
        "from sklearn.model_selection import train_test_split #싸이킷런에 있는 데이터를 train과 test dataset으로 나누어주는 함수 import\n",
        "from sklearn.metrics import classification_report #싸이킷런에 있는 분류 결과에 대한 시각화를 위한 import\n",
        "\n",
        "# (2) 데이터 준비하기\n",
        "digits = load_digits() #digits 데이터 전체를 불러온다.\n",
        "digits_data = digits.data #digits 데이터의 data컬럼을 분류해 digits_data 변수에 담는다.\n",
        "digits_label = digits.target #digits 데이터의 target컬럼을 분류해 digits_label 변수에 담는다.\n",
        "\n",
        "\n",
        "# (3) 데이터 이해하기\n",
        "print(\"<<digits 정보 이해하기>>\")\n",
        "# 데이터셋의 기본 정보 출력\n",
        "print(\"- 변수와 메서드 : \", dir(digits))\n",
        "print(\"- 데이터셋 키 : \", digits.keys())\n",
        "print(\"- 특성 이름 : \", digits.feature_names)\n",
        "print(\"- 타겟 이름 : \", digits.target_names)\n",
        "print(\"- 데이터의 첫 번째 샘플 : \", digits_data[0])\n",
        "print(\"- 타겟의 첫 번째 샘플 : \", digits_label[0])\n",
        "\n",
        "# 데이터의 크기 확인\n",
        "print(\"- 데이터 크기 : \", digits_data.shape)\n",
        "print(\"- 타겟 크기 : \", digits_label.shape)\n",
        "\n",
        "print()\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "df_class_counts = pd.DataFrame(pd.Series(digits.target).value_counts())\n",
        "df_class_counts.sort_index()\n",
        "print(df_class_counts.sort_index())\n",
        "\n",
        "print()\n",
        "\n",
        "plt.imshow(digits.data[0].reshape(8, 8), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print('-' * 100 )\n",
        "\n",
        "for i in range(10):\n",
        "  plt.subplot(2, 5, i+1)\n",
        "  plt.imshow(digits.data[i].reshape(8, 8), cmap='gray')\n",
        "  plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print('-' * 100 )\n",
        "\n",
        "# 데이터 Describe\n",
        "digits_df = pd.DataFrame(data=digits_data, columns=digits.feature_names)\n",
        "digits_df.describe()\n",
        "\n",
        "print('-' * 100 )\n",
        "\n",
        "# (4) train, test 데이터 분리하기\n",
        "#train_test_split()를 사용하여 X값, y값을 각각 train data와 test data로 나눈다. 함수에 들어 갈 파라미터로는 x,y가 들어가고\n",
        "#test_size는 몇대몇으로 나눌지 정하는 옵션, random_state는 랜덤 패턴의 값을 지정한다.\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits_data,\n",
        "                                                    digits_label,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=15)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier #싸이킷런에 있는 결정트리분류기를 사용하기 위한 import\n",
        "from sklearn.ensemble import RandomForestClassifier #랜덤포레스트라는 분류기를 사용하기 위한 import\n",
        "from sklearn import svm #Support Vector Machine을 사용하기 위해 import\n",
        "from sklearn.linear_model import SGDClassifier #선형분류기인 SGDClassifier를 사용하기 위한 import\n",
        "from sklearn.linear_model import LogisticRegression #선형분류기인 LogisticRegression를 사용하기 위한 import\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix #싸이킷런에 있는 분류 결과에 대한 시각화를 위한 import\n",
        "\n",
        "# (5) 다양한 모델로 학습 및 예측하기\n",
        "# (5-1) Decision Tree 사용해 보기\n",
        "print('<<Decision Tree>>')\n",
        "print()\n",
        "decision_tree = DecisionTreeClassifier(random_state=32) #결정트리분류기의 객체 생성\n",
        "decision_tree.fit(X_train, y_train) #분류기에 x와 y의 훈련 데이터를 넣어 훈련\n",
        "decision_tree_pred = decision_tree.predict(X_test) #훈련된 분류기에 X_test라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인 => y_pred(decision_tree_pred)를 각 모델별로 새로 계산하도록 변경(결과가 잘못된 해석으로 이어질 수 있음을 예방하기 위해 / classification_report와 confusion_matrix가 올바른 예측값을 참조하도록 하기 위해)\n",
        "print(classification_report(y_test, decision_tree_pred)) # 결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred(decision_tree_pred) 값을 넣어 확인\n",
        "print()\n",
        "print(\"confussion matrix\")\n",
        "decision_tree_conf_matrix = confusion_matrix(y_test, decision_tree_pred)\n",
        "decision_tree_accuracy = accuracy_score(y_test, decision_tree_pred)\n",
        "print(decision_tree_conf_matrix)\n",
        "print()\n",
        "print(\"Decision Tree Accuracy : \", decision_tree_accuracy*100,'\\n')\n",
        "print()\n",
        "print('-' * 100 )\n",
        "\n",
        "\n",
        "# (5-2) Random Forest 사용해 보기\n",
        "print('<<Random Forest>>')\n",
        "print()\n",
        "random_forest = RandomForestClassifier(random_state=32) #RandomForest분류기의 객체 생성\n",
        "random_forest.fit(X_train, y_train) #분류기에 x와 y의 훈련 데이터를 넣어 훈련\n",
        "random_forest_pred = random_forest.predict(X_test) #훈련된 분류기에 X_test라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인 => y_pred(random_forest_pred)를 각 모델별로 새로 계산하도록 변경(결과가 잘못된 해석으로 이어질 수 있음을 예방하기 위해 / classification_report와 confusion_matrix가 올바른 예측값을 참조하도록 하기 위해)\n",
        "print(classification_report(y_test, random_forest_pred)) # 결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred(random_forest_pred) 값을 넣어 확인\n",
        "print()\n",
        "print(\"confussion matrix\")\n",
        "random_forest_conf_matrix = confusion_matrix(y_test, random_forest_pred)\n",
        "random_forest_accuracy = accuracy_score(y_test, random_forest_pred)\n",
        "print(random_forest_conf_matrix)\n",
        "print()\n",
        "print(\"Random Forest Accuracy : \", random_forest_accuracy*100,'\\n')\n",
        "print()\n",
        "print('-' * 100 )\n",
        "\n",
        "# (5-3) SVM 사용해 보기\n",
        "print('<<SVM_model>>')\n",
        "print()\n",
        "svm_model = svm.SVC(random_state=32) #분류기의 객체 생성\n",
        "svm_model.fit(X_train, y_train) #분류기에 x와 y의 훈련 데이터를 넣어 훈련\n",
        "svm_model_pred = svm_model.predict(X_test) #훈련된 분류기에 X_test라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인 => y_pred(svm_model_pred)를 각 모델별로 새로 계산하도록 변경(결과가 잘못된 해석으로 이어질 수 있음을 예방하기 위해 / classification_report와 confusion_matrix가 올바른 예측값을 참조하도록 하기 위해)\n",
        "print(classification_report(y_test, svm_model_pred)) # 결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred(svm_model_pred) 값을 넣어 확인\n",
        "print()\n",
        "print(\"confussion matrix\")\n",
        "svm_model_conf_matrix = confusion_matrix(y_test, svm_model_pred)\n",
        "svm_model_accuracy = accuracy_score(y_test, svm_model_pred)\n",
        "print(svm_model_conf_matrix)\n",
        "print()\n",
        "print(\"SVM_model Accuracy : \", svm_model_accuracy*100,'\\n')\n",
        "print()\n",
        "print('-' * 100 )\n",
        "\n",
        "# (5-4) SGD Classifier 사용해 보기\n",
        "print('<<SGD Classifier>>')\n",
        "print()\n",
        "sgd_model = SGDClassifier(random_state=32) #분류기의 객체 생성\n",
        "sgd_model.fit(X_train, y_train) #분류기에 x와 y의 훈련 데이터를 넣어 훈련\n",
        "sgd_model_pred = sgd_model.predict(X_test) #훈련된 분류기에 X_test라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인 => y_pred(sgd_model_pred)를 각 모델별로 새로 계산하도록 변경(결과가 잘못된 해석으로 이어질 수 있음을 예방하기 위해 / classification_report와 confusion_matrix가 올바른 예측값을 참조하도록 하기 위해)\n",
        "print(classification_report(y_test, sgd_model_pred)) # 결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred(sgd_model_pred) 값을 넣어 확인\n",
        "print()\n",
        "print(\"confussion matrix\")\n",
        "sgd_model_conf_matrix = confusion_matrix(y_test, sgd_model_pred)\n",
        "sgd_model_accuracy = accuracy_score(y_test, sgd_model_pred)\n",
        "print(sgd_model_conf_matrix)\n",
        "print()\n",
        "print(\"SGD Classifier Accuracy : \", sgd_model_accuracy*100,'\\n')\n",
        "print()\n",
        "print('-' * 100 )\n",
        "\n",
        "\n",
        "# (5-5) Logistic Regression 사용해 보기\n",
        "print('<<Logistic Regression>>')\n",
        "print()\n",
        "logistic_model = LogisticRegression(random_state=32, max_iter=1000) #분류기의 객체 생성 (디폴트 max_iter 값이 충분하지 않을 수 있어, max_iter=1000을 설정해 경고 방지)\n",
        "logistic_model.fit(X_train, y_train) #분류기에 x와 y의 훈련 데이터를 넣어 훈련\n",
        "logistic_model_pred = logistic_model.predict(X_test) #훈련된 분류기에 X_test라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인 => y_pred(logistic_model_pred)를 각 모델별로 새로 계산하도록 변경(결과가 잘못된 해석으로 이어질 수 있음을 예방하기 위해 / classification_report와 confusion_matrix가 올바른 예측값을 참조하도록 하기 위해)\n",
        "print(classification_report(y_test, logistic_model_pred)) # 결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred(logistic_model_pred) 값을 넣어 확인\n",
        "print()\n",
        "print(\"confussion matrix\")\n",
        "logistic_model_conf_matrix = confusion_matrix(y_test, logistic_model_pred)\n",
        "logistic_model_accuracy = accuracy_score(y_test, logistic_model_pred)\n",
        "print(logistic_model_conf_matrix)\n",
        "print()\n",
        "print(\"Logistic Regression Accuracy : \", logistic_model_accuracy*100,'\\n')\n",
        "print()\n",
        "print('-' * 100 )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 평가\n",
        "\n",
        "1. Decision Tree\n",
        "* precision/recall/f1-score : 평균값이 각 0.85/0.84/0.84\n",
        "* confussion matrix :\n",
        "[[29  0  0  0  0  0  0  0  2  0]\n",
        " [ 0 31  3  1  1  0  1  0  1  0]\n",
        " [ 0  1 33  1  0  1  0  0  1  1]\n",
        " [ 0  0  0 22  0  1  1  0  2  1]\n",
        " [ 0  0  0  1 32  0  4  3  0  1]\n",
        " [ 0  0  3  0  0 31  0  0  1  0]\n",
        " [ 0  1  2  0  0  1 34  0  0  0]\n",
        " [ 0  0  0  1  0  0  0 31  0  2]\n",
        " [ 0  2  3  0  0  2  0  0 26  2]\n",
        " [ 0  3  2  0  0  2  0  0  2 34]]\n",
        "\n",
        "* Accuracy : 약 84.17%\n",
        "---\n",
        "\n",
        "2. Random Forest\n",
        "* precision/recall/f1-score : 평균값이 각 0.98/0.98/0.98\n",
        "* confussion matrix :\n",
        "[[29  0  0  0  2  0  0  0  0  0]\n",
        " [ 0 37  0  0  0  1  0  0  0  0]\n",
        " [ 0  0 38  0  0  0  0  0  0  0]\n",
        " [ 0  0  0 26  0  0  0  0  1  0]\n",
        " [ 0  0  0  0 41  0  0  0  0  0]\n",
        " [ 0  0  0  0  0 35  0  0  0  0]\n",
        " [ 1  1  0  0  0  0 36  0  0  0]\n",
        " [ 0  0  0  0  0  0  0 34  0  0]\n",
        " [ 0  1  0  0  0  0  0  0 34  0]\n",
        " [ 0  0  0  0  0  0  0  0  1 42]]\n",
        "\n",
        "* Accuracy : 약 97.78%\n",
        "---\n",
        "\n",
        "3. SVM_model\n",
        "* precision/recall/f1-score : 평균값이 각 0.98/0.98/0.98\n",
        "* confussion matrix :\n",
        "[[30  0  0  0  1  0  0  0  0  0]\n",
        " [ 0 38  0  0  0  0  0  0  0  0]\n",
        " [ 0  0 38  0  0  0  0  0  0  0]\n",
        " [ 0  0  0 26  0  0  0  0  1  0]\n",
        " [ 0  0  0  0 40  0  0  0  0  1]\n",
        " [ 0  0  0  0  0 35  0  0  0  0]\n",
        " [ 0  0  0  0  0  0 38  0  0  0]\n",
        " [ 0  0  0  0  0  0  0 34  0  0]\n",
        " [ 0  2  0  0  0  0  0  0 33  0]\n",
        " [ 0  0  0  1  0  0  0  0  0 42]]\n",
        "\n",
        "* Accuracy : 약 98.33%\n",
        "---\n",
        "\n",
        "4. SGD Classifier\n",
        "* precision/recall/f1-score : 평균값이 각 0.95/0.94/0.94\n",
        "* confussion matrix :\n",
        "[[30  0  0  0  1  0  0  0  0  0]\n",
        " [ 0 31  0  0  0  0  0  0  7  0]\n",
        " [ 0  0 36  0  0  0  0  0  2  0]\n",
        " [ 0  0  0 23  0  1  0  0  2  1]\n",
        " [ 0  0  0  0 40  0  0  0  1  0]\n",
        " [ 0  0  0  0  0 35  0  0  0  0]\n",
        " [ 0  0  0  0  0  0 37  0  1  0]\n",
        " [ 0  0  0  0  0  0  0 34  0  0]\n",
        " [ 0  1  0  0  0  0  0  0 34  0]\n",
        " [ 0  0  0  1  0  0  0  1  4 37]]\n",
        "\n",
        "* Accuracy : 약 93.61%\n",
        "---\n",
        "\n",
        "5. Logistic Regression\n",
        "* precision/recall/f1-score : 평균값이 각 0.97/0.97/0.97\n",
        "* confussion matrix :\n",
        "[[30  0  0  0  1  0  0  0  0  0]\n",
        " [ 0 37  0  0  0  0  0  0  1  0]\n",
        " [ 0  1 37  0  0  0  0  0  0  0]\n",
        " [ 0  0  0 25  0  1  0  0  1  0]\n",
        " [ 0  0  0  0 40  0  0  0  1  0]\n",
        " [ 0  0  0  0  0 34  0  0  0  1]\n",
        " [ 0  1  0  0  0  0 37  0  0  0]\n",
        " [ 0  0  0  0  0  0  0 34  0  0]\n",
        " [ 0  0  0  0  1  0  0  0 34  0]\n",
        " [ 0  0  0  1  0  0  0  0  1 41]]\n",
        "\n",
        "* Accuracy : 약 96.94%\n",
        "---\n",
        "# 선택한 평가지표\n",
        "* 정밀도, 재현율, 정확도가 가장 좋은 SVM_model이 적절한 모델인 것으로 판단\n",
        "---"
      ],
      "metadata": {
        "id": "UNwB_Ki7aWbX"
      }
    }
  ]
}